{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras as k\n",
    "from keras import layers as l\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(layer_in, n_filters, batchnorm=True):\n",
    "    # Initialize weights\n",
    "    init = k.initializers.RandomNormal(0., 0.02)    # Add the downsampling\n",
    "    d = l.Conv2D(n_filters, (4,4,), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "    if(batchnorm):\n",
    "        d = l.BatchNormalization()(d, training=True)\n",
    "    d = l.LeakyReLU(alpha=0.2)(d)\n",
    "    return d\n",
    "\n",
    "def decoder(layer_in, skip_in, n_filters, dropout=True):\n",
    "    # Initialize weights\n",
    "    init = k.initializers.RandomNormal(0., 0.02)    # Add the upsampling\n",
    "    u = l.Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "    u = l.BatchNormalization()(u, training=True)\n",
    "    if(dropout):\n",
    "        u = l.Dropout(0.5)(u, training=True)\n",
    "    # Merge\n",
    "    u = l.Concatenate()([u, skip_in])\n",
    "    u = l.Activation('relu')(u)\n",
    "    return u\n",
    "\n",
    "def generator(image_shape=(256,256,3)):\n",
    "    # Initialize weights\n",
    "    init = k.initializers.RandomNormal(0., 0.02)\n",
    "    # Input\n",
    "    in_image = l.Input(shape=image_shape)\n",
    "\n",
    "    # Encode\n",
    "    e1 = encoder(in_image, 64, False)\n",
    "    e2 = encoder(e1, 128)\n",
    "    e3 = encoder(e2, 256)\n",
    "    e4 = encoder(e3, 512)\n",
    "    e5 = encoder(e4, 512)\n",
    "\n",
    "    # Bottleneck\n",
    "    b = l.Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e5)\n",
    "    b = l.Activation('relu')(b)\n",
    "\n",
    "    # Decode\n",
    "    d1 = decoder(b, e5, 512)\n",
    "    d2 = decoder(d1, e4, 512)\n",
    "    d3 = decoder(d2, e3, 256, dropout=False)\n",
    "    d4 = decoder(d3, e2, 128, dropout=False)\n",
    "    d5 = decoder(d4, e1, 64, dropout=False)\n",
    "\n",
    "    # Output\n",
    "    g = l.Conv2DTranspose(3, (4,4), strides=(2,2), padding = 'same', kernel_initializer=init)(d5)\n",
    "    out_image = l.Activation('tanh')(g)\n",
    "\n",
    "    # Define model\n",
    "    model = k.Model(in_image, out_image)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(image_shape):\n",
    "    init = k.initializers.RandomNormal(0., 0.02)\n",
    "    input_image = l.Input(shape=image_shape)\n",
    "    target_image = l.Input(shape=image_shape)\n",
    "    d = l.Concatenate()([input_image, target_image])\n",
    "    \n",
    "    d = l.SpectralNormalization(l.Conv2D(64, (4, 4), strides=2, padding='same', kernel_initializer=init))(d)\n",
    "    d = l.LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = l.SpectralNormalization(l.Conv2D(128, (4, 4), strides=2, padding='same', kernel_initializer=init))(d)\n",
    "    d = l.LayerNormalization()(d, training=True)\n",
    "    d = l.LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = l.SpectralNormalization(l.Conv2D(256, (4, 4), strides=2, padding='same', kernel_initializer=init))(d)\n",
    "    d = l.LayerNormalization()(d, training=True)\n",
    "    d = l.LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = l.SpectralNormalization(l.Conv2D(512, (4, 4), strides=1, padding='same', kernel_initializer=init))(d)\n",
    "    d = l.LayerNormalization()(d, training=True)\n",
    "    d = l.LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = l.SpectralNormalization(l.Conv2D(1, (4, 4), strides=1, padding='same', kernel_initializer=init))(d)\n",
    "    patch_output = l.Activation('sigmoid')(d)\n",
    "    \n",
    "    model = k.Model([input_image, target_image], patch_output)\n",
    "    opt = k.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "disc_ce_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = disc_ce_loss(tf.ones_like(real_output) * 0.9, real_output)\n",
    "\n",
    "    generated_loss = disc_ce_loss(tf.zeros_like(fake_output), fake_output)\n",
    "\n",
    "    total_loss = real_loss + generated_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan(g_model, d_model, image_shape):\n",
    "    for layer in d_model.layers:\n",
    "        if not isinstance(layer, l.BatchNormalization):\n",
    "            layer.trainable = False\n",
    "    in_src = l.Input(shape=image_shape)\n",
    "    gen_out = g_model(in_src)\n",
    "    dis_out = d_model([in_src, gen_out])\n",
    "\n",
    "    model = k.Model(in_src, [dis_out, gen_out])\n",
    "    \n",
    "    opt = k.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(rgb_dir, ndvi_dir, image_shape=(256,256,3)):\n",
    "    # Load images\n",
    "    rgb_images = sorted(glob.glob(os.path.join(rgb_dir, '*.jpg')))\n",
    "    ndvi_images = sorted(glob.glob(os.path.join(ndvi_dir, '*.jpg')))\n",
    "    # Check if the number of images is the same\n",
    "    if len(rgb_images) != len(ndvi_images):\n",
    "        raise ValueError(\"Number of RGB and NDVI images do not match.\")\n",
    "    \n",
    "    # Load and resize images\n",
    "    rgb_images = [k.preprocessing.image.load_img(img, target_size=image_shape) for img in rgb_images]\n",
    "    ndvi_images = [k.preprocessing.image.load_img(img, target_size=image_shape) for img in ndvi_images]\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    rgb_images = np.array([k.preprocessing.image.img_to_array(img) / 127.5 - 1 for img in rgb_images])\n",
    "    ndvi_images = np.array([k.preprocessing.image.img_to_array(img) / 127.5 - 1 for img in ndvi_images])\n",
    "    \n",
    "    return rgb_images, ndvi_images\n",
    "\n",
    "def real_pairs(dataset, n_samples, patch_shape):\n",
    "    # Unpack\n",
    "    trainA, trainB = dataset\n",
    "\n",
    "    # Pick random\n",
    "    ix = np.random.randint(0,trainA.shape[0], n_samples)\n",
    "    X1, X2 = trainA[ix], trainB[ix]\n",
    "\n",
    "    # Label 1 (Real)\n",
    "    y = tf.ones((n_samples, patch_shape, patch_shape, 1))\n",
    "    return [X1, X2], y\n",
    "\n",
    "def fake_pairs(g_model, samples, patch_shape):\n",
    "    # Generate fake\n",
    "    X = g_model.predict(samples, batch_size=32)\n",
    "    # Label 0 (Fake)\n",
    "    y = tf.zeros((len(X), patch_shape, patch_shape, 1))\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(step, g_model, dataset, n_samples = 3):\n",
    "    # Select an input sample\n",
    "    [X_realA, X_realB], _ = real_pairs(dataset, n_samples, 1)\n",
    "\n",
    "    # Generate a fake input sample\n",
    "    X_fakeB, _ = fake_pairs(g_model, X_realA, 1)\n",
    "\n",
    "    # Scale pixel values\n",
    "    X_realA = (X_realA + 1) / 2.0\n",
    "    X_fakeB = (X_fakeB + 1) / 2.0\n",
    "    X_realB = (X_realB + 1) / 2.0\n",
    "\n",
    "    # Plot real images\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(3, n_samples, 1 + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_realA[i])\n",
    "    \n",
    "    # Plot fake image\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(3, n_samples, 1 + n_samples + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_fakeB[i])\n",
    "\n",
    "    # Plot real image\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(3, n_samples, 1 + n_samples * 2 + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_realB[i])\n",
    "    \n",
    "    filename1 = 'plot_%06d.png' % (step + 1)\n",
    "    plt.savefig(filename1)\n",
    "    plt.close()\n",
    "    filename2 = 'model_%06d.h5' % (step + 1)\n",
    "    g_model.save(filename2)\n",
    "    print('>Saved: %s and %s' % (filename1, filename2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(images, noise_factor=0.05):\n",
    "    noise = noise_factor * tf.random.normal(shape=images.shape)\n",
    "    return images + noise\n",
    "\n",
    "def train(g_model, d_model, gan_model, dataset, epochs=100, batch = 1):\n",
    "    # Determine the output shape\n",
    "    n_patch = d_model.output_shape[1]\n",
    "\n",
    "    # Unpack data\n",
    "    trainA, trainB = dataset\n",
    "\n",
    "    # Calcuate batches per epoch\n",
    "    bat_per_epoch = int(len(trainA) / batch)\n",
    "    \n",
    "    # Calculate iterations\n",
    "    n_steps = bat_per_epoch * epochs\n",
    "\n",
    "    # Enumerate epochs\n",
    "    for i in range(n_steps):\n",
    "        # Select real samples\n",
    "        [X_realA, X_realB], y_real = real_pairs([trainA, trainB], batch, n_patch)\n",
    "\n",
    "        # Select fake samples\n",
    "        X_fakeB, y_fake = fake_pairs(g_model, X_realA, n_patch)\n",
    "\n",
    "        # Add noise to the real images\n",
    "        X_realA = add_noise(X_realA, noise_factor=0.05)\n",
    "        X_realB = add_noise(X_realB, noise_factor=0.05)\n",
    "\n",
    "        # Add noise to the fake images\n",
    "        X_fakeB = add_noise(X_fakeB, noise_factor=0.05)\n",
    "        \n",
    "        # Update discriminator\n",
    "        d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real, return_dict=True)\n",
    "        d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake, return_dict=True)\n",
    "        \n",
    "        d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real, return_dict=True)\n",
    "        d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake, return_dict=True)\n",
    "\n",
    "        # Update generator\n",
    "        g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
    "\n",
    "        # Summarize performance\n",
    "        print(f\">{i+1}, d1[ a:{d_loss1['accuracy']:.2f}, l:{d_loss1['loss']:.2f}] \\td2[ a:{d_loss2['accuracy']:.2f}, l:{d_loss2['loss']:.2f}] \\tg[{g_loss:.2f}]\")\n",
    "        if (i+1) % (bat_per_epoch/2) == 0:\n",
    "            performance(i, g_model, [trainA, trainB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_images('dataset/train/inputs/RGB', 'dataset/train/inputs/NDVI', image_shape=(256,256,3))\n",
    "generator = generator()\n",
    "discriminator = discriminator((256, 256, 3))\n",
    "gan_model = gan(generator, discriminator, (256, 256, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(g_model=generator, d_model=discriminator,gan_model=gan_model, dataset=dataset, epochs=100, batch=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
