{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.colors as mcolors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Aligns then saves two images using opencv.cv2\n",
    "NOTE:   The reference image is the one that is left unchanged. The target image is warped to\n",
    "        fit the reference image. \n",
    "        \n",
    "        Recommend having the wider angled image be the target.\n",
    "'''\n",
    "def align_image(reference_dir, target_dir):\n",
    "    sift = cv2.SIFT_create()\n",
    "    reference_img = cv2.imread(reference_dir)\n",
    "    target_img = cv2.imread(target_dir)\n",
    "\n",
    "    keypointsRef, descriptorsRef = sift.detectAndCompute(reference_img, None)\n",
    "    keypointsTarget, descriptorsTarget = sift.detectAndCompute(target_img,None)\n",
    "    if keypointsRef is None or keypointsTarget is None:\n",
    "        raise ValueError(\"Failed to detect keypoints.\")\n",
    "    if descriptorsRef is None or descriptorsTarget is None:\n",
    "        raise ValueError(\"Failed to compute descriptors.\")\n",
    "    matcher = cv2.FlannBasedMatcher({\"algorithm\": 1, \"trees\": 5}, {\"checks\": 50})\n",
    "    matches = matcher.knnMatch(descriptorsRef, descriptorsTarget, k = 2)\n",
    "\n",
    "    good_matches = [m for m, n in matches if m.distance < 0.75 * n.distance]\n",
    "\n",
    "    pointsRef = np.float32([keypointsRef[m.queryIdx].pt for m in good_matches]).reshape(-1,1,2)\n",
    "    pointsTarget = np.float32([keypointsTarget[m.trainIdx].pt for m in good_matches]).reshape(-1,1,2)\n",
    "\n",
    "    homography, _ = cv2.findHomography(pointsTarget, pointsRef, cv2.RANSAC)\n",
    "    \n",
    "    aligned_img = cv2.warpPerspective(target_img, homography, (2560,2560))\n",
    "\n",
    "    cv2.imwrite(target_dir, aligned_img)\n",
    "\n",
    "'''\n",
    "Driver method that aligns two directories of image pairs. \n",
    "\n",
    "NOTE:   It is assumed that the directories have been cleaned, so errors of that nature are\n",
    "        not properly handled.\n",
    "'''\n",
    "def align_dir(reference_dir, target_dir):\n",
    "    ref_list = os.listdir(reference_dir)\n",
    "    tar_list = os.listdir(target_dir)\n",
    "    for i in range(len(os.listdir(reference_dir))):\n",
    "        ref_path = os.path.join(reference_dir, ref_list[i])\n",
    "        tar_path = os.path.join(target_dir, tar_list[i])\n",
    "        try:\n",
    "            align_image(ref_path, tar_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to align {ref_list[i]} and {tar_list[i]}: {e}\")\n",
    "\n",
    "        print(f\"Aligning: {i+1}/{len(ref_list)}\\t\\t\\t\\t\\t\\t\\t\\t\", end=\"\\r\")\n",
    "\n",
    "\n",
    "'''\n",
    "Splits an image into a grid with dimensions X by Y where grid_size = [x,y]\n",
    "Saves image tiles to output_dir using the name image_name\n",
    "\n",
    "NOTE:   Ensure images are aligned correctly before splitting the images to ensure\n",
    "        the tiles are properly aligned\n",
    "'''\n",
    "def split_image(image, image_name, output_dir, grid_size):\n",
    "    # Open the image file\n",
    "    image_width, image_height = image.size\n",
    "\n",
    "    # Calculate the size of each tile\n",
    "    tile_width = image_width // grid_size[0]\n",
    "    tile_height = image_height // grid_size[1]\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Loop through the grid and save smaller images\n",
    "    for row in range(grid_size[1]):\n",
    "        for col in range(grid_size[0]):\n",
    "            # Calculate the coordinates of the tile\n",
    "            left = col * tile_width\n",
    "            upper = row * tile_height\n",
    "            right = left + tile_width\n",
    "            lower = upper + tile_height\n",
    "\n",
    "            # Crop the tile from the image\n",
    "            cropped_image = image.crop((left, upper, right, lower))\n",
    "\n",
    "            # Save the cropped image\n",
    "            tile_filename = f\"{image_name[:-4]}_tile_{row}_{col}.jpg\"\n",
    "            cropped_image.save(os.path.join(output_dir, tile_filename))\n",
    "\n",
    "    # print(f\"Image successfully split into {grid_size[0]}x{grid_size[1]} grid and saved in {output_dir}.\")\n",
    "'''\n",
    "Driver method that splits images from a directory into a grid with dimensions X by Y where grid_size = [x,y]\n",
    "'''\n",
    "def split_dir(raw_dir, process_dir, grid):\n",
    "    raw_files = os.listdir(raw_dir)\n",
    "    for i in range(len(raw_files)):\n",
    "        raw_path = os.path.join(raw_dir, raw_files[i])\n",
    "        try:\n",
    "            with Image.open(raw_path) as img:\n",
    "                split_image(img, raw_files[i], process_dir, grid)\n",
    "                print(f\"Splitting: {i+1}/{len(raw_files)} images into {grid[0]}x{grid[1]} grid and saved to {process_dir}\\t\\t\\t\\t\\t\\t\\t\\t\", end=\"\\r\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to split {raw_files[i]}: {e}\")\n",
    "        \n",
    "'''\n",
    "Resizes the images found in raw_dir to be target_size and saves them to dst_dir.\n",
    "\n",
    "TODO:   File endings are not checked, so ensure directories contain only image types or\n",
    "        impliment error handling\n",
    "'''\n",
    "def resize_dir(raw_dir, dst_dir, target_size):\n",
    "    raw_files = os.listdir(raw_dir)\n",
    "    for i in range(len(raw_files)):\n",
    "        raw_path = os.path.join(raw_dir, raw_files[i])\n",
    "        dst_path = os.path.join(dst_dir, raw_files[i])\n",
    "        if not os.path.isfile(raw_path):\n",
    "            continue\n",
    "        try:\n",
    "            with Image.open(raw_path) as img:\n",
    "                img_resized = img.resize(target_size, Image.Resampling.LANCZOS)\n",
    "                img_resized.save(dst_path)\n",
    "                print(f\"Resizing: {i+1}/{len(raw_files)} images saved to {dst_dir}\\t\\t\\t\\t\\t\\t\\t\\t\", end=\"\\r\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {raw_files[i]}: {e}, {target_size}\")\n",
    "\n",
    "\n",
    "'''\n",
    "Converts a raw NDVI value into a grayscale value\n",
    "'''\n",
    "def mono(val, range, new_range):\n",
    "    converted_value = (val + 1) * 127.5\n",
    "    return int(round(converted_value))\n",
    "\n",
    "\n",
    "'''\n",
    "Gets the timestamps to match and append.\n",
    "\n",
    "NOTE: Adjust delimiter, timestamps_pos, and extension to match your format\n",
    "'''\n",
    "def get_timestamps(dir,  delimiter = \"%,\", timestamps_pos = -1, extension = \".jpg\"):\n",
    "    timestamps = set()\n",
    "    ts=[]\n",
    "    for filename in os.listdir(dir):\n",
    "        if filename.__contains__(extension):\n",
    "            timestamp = filename.split(delimiter)[timestamps_pos].split(extension)[0]\n",
    "            timestamps.add(timestamp)\n",
    "            ts.append(timestamp)\n",
    "    return timestamps, ts\n",
    "\n",
    "'''\n",
    "Generates an NDVI image map given the file path to a red and a nir image.\n",
    "Saves the generated image to ndvi_path with the same timestamp as the parents.\n",
    "'''\n",
    "def create_ndvi_image(red_path, noir_path, ndvi_path, stamp):\n",
    "    red = Image.open(red_path)\n",
    "    noir = Image.open(noir_path).resize(red.size)\n",
    "\n",
    "    red_pix = np.array(red)\n",
    "    noir_pix = np.array(noir)\n",
    "\n",
    "    mono_ndvi_pix = np.zeros(red_pix.shape)\n",
    "\n",
    "    for x in range(len(noir_pix)):\n",
    "        for y in range(len(noir_pix[x])):\n",
    "            nir = int(np.average(noir_pix[x][y]))\n",
    "            red = int(np.average(red_pix[x][y]))\n",
    "            ndvi_value = (nir - red) / (nir + red)\n",
    "            mono_ndvi_pix[x][y] = mono(ndvi_value, [-1,1], [0,255])\n",
    "    mono_ndvi = Image.fromarray(mono_ndvi_pix.astype(np.uint8))\n",
    "    mono_ndvi.save(ndvi_path + \"mono_ndvi\" + str(stamp) + \".jpg\")\n",
    "\n",
    "\n",
    "'''\n",
    "Driver method to generate ndvi image maps from the two parent directories.\n",
    "'''\n",
    "def generate_ndvi_dir(red_dir, noir_dir, ndvi_dir):\n",
    "    red_list = os.listdir(red_dir)\n",
    "    noir_list = os.listdir(noir_dir)\n",
    "    timestamps = get_timestamps(red_dir)[1]\n",
    "    for i in range(len(red_list)):\n",
    "        red_path = os.path.join(red_dir,red_list[i])\n",
    "        noir_path = os.path.join(noir_dir, noir_list[i])\n",
    "        stamp = timestamps[i]\n",
    "        create_ndvi_image(red_path, noir_path, ndvi_dir, stamp)\n",
    "        print(f\"Generating NDVI Map: {i+1}/{len(red_list)} images saved to {ndvi_dir}\\t\\t\\t\\t\\t\\t\\t\\t\", end=\"\\r\")\n",
    "\n",
    "'''\n",
    "Removes any images that do not have a pair using the timestamps.\n",
    "'''\n",
    "def clean_nonpairs(rgb_dir, noir_dir, delimiter = \"%,\", timestamps_pos = -1, extension = \".jpg\"):\n",
    "    timestampsRGB = get_timestamps(rgb_dir, delimiter=delimiter, timestamps_pos=timestamps_pos, extension=extension)[0]\n",
    "    timestampsNOIR = get_timestamps(noir_dir, delimiter=delimiter, timestamps_pos=timestamps_pos, extension=extension)[0]\n",
    "\n",
    "    common_timestamps = timestampsNOIR.intersection(timestampsRGB)\n",
    "\n",
    "    for filename in os.listdir(rgb_dir):\n",
    "        if filename.endswith(extension):\n",
    "            timestamp = filename.split(delimiter)[timestamps_pos].split(extension)[0]\n",
    "            if timestamp not in common_timestamps:\n",
    "                os.remove(os.path.join(rgb_dir, filename))\n",
    "                print(f\"Removed {filename} from {rgb_dir}\")\n",
    "\n",
    "    for filename in os.listdir(noir_dir):\n",
    "        if filename.endswith(extension):\n",
    "            timestamp = filename.split(delimiter)[timestamps_pos].split(extension)[0]\n",
    "            if timestamp not in common_timestamps:\n",
    "                os.remove(os.path.join(noir_dir, filename))\n",
    "                print(f\"Removed {filename} from {noir_dir}\")\n",
    "\n",
    "'''\n",
    "Converts the directory containing NoIR + IR pass images from RGB to greyscale \n",
    "'''\n",
    "def make_ir_mono(src_dir, dst_dir):\n",
    "    files = os.listdir(src_dir)\n",
    "    for i in range(len(files)):\n",
    "        raw_path = os.path.join(src_dir, files[i])\n",
    "        dst_path = os.path.join(dst_dir, files[i])\n",
    "        try:\n",
    "            with Image.open(raw_path) as img:\n",
    "                mono = img.convert('L')\n",
    "                mono.save(dst_path)\n",
    "        except Exception as e:\n",
    "            print(f\"{raw_path} ---> {dst_path}\")\n",
    "            print(f\"Failed to apply IR-mono to {files[i]}: {e}\")\n",
    "        \n",
    "        print(f\"Making IR Mono: {i+1}/{len(files)} images saved to {dst_dir}\\t\\t\\t\\t\\t\\t\\t\\t\", end=\"\\r\")\n",
    "\n",
    "\n",
    "'''\n",
    "Converts the directory containing RGB images to greyscale images containing only the value for the red channel\n",
    "'''\n",
    "def make_red_mono(src_dir, dst_dir):\n",
    "    files = os.listdir(src_dir)\n",
    "    for i in range(len(files)):\n",
    "        raw_path = os.path.join(src_dir, files[i])\n",
    "        dst_path = os.path.join(dst_dir, files[i])\n",
    "        try:\n",
    "            with Image.open(raw_path) as img:\n",
    "                rgb = img.convert('RGB')\n",
    "                red, blue, green = rgb.split()\n",
    "                red.save(dst_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to apply red-mono to {files[i]}: {e}\")\n",
    "        print(f\"Making RED Mono: {i+1}/{len(files)} images saved to {dst_dir}\\t\\t\\t\\t\\t\\t\\t\\t\", end=\"\\r\")\n",
    "\n",
    "\n",
    "'''\n",
    "Maps a greyscale value to an RGB value according to the defined gradient\n",
    "'''\n",
    "def map_to_gradient(value):\n",
    "    \"\"\"Maps a value (0-255) to a blue-red-yellow-green gradient.\"\"\"\n",
    "    colors = [(0, 0, 1),  # Blue (0) (-1)\n",
    "              (1, 0, 0),  # Red (85) (-.33)\n",
    "              (1, 1, 0),  # Yellow (.33)\n",
    "              (0, 1, 0)]  # Green (1)]\n",
    "    \n",
    "    norm_value = value / 255.0  # Normalize the value to 0-1\n",
    "    color_map = mcolors.LinearSegmentedColormap.from_list(\"custom_gradient\", colors)\n",
    "    \n",
    "    return color_map(norm_value)  # Returns an RGBA tuple\n",
    "\n",
    "\n",
    "'''\n",
    "Generate gradient NDVI map for analysis.\n",
    "\n",
    "NOTE: Dr. Menon recommends not using this as training input, and only for analysis\n",
    "'''\n",
    "def create_ndvi_gradient_image(ndvi_path, gradient_path, stamp):\n",
    "    ndvi = Image.open(ndvi_path)\n",
    "    ndvi_pix = np.array(ndvi)\n",
    "    print(ndvi_pix.shape[0:2])\n",
    "    grad_ndvi = Image.new(\"RGB\", (ndvi_pix.shape[0:2]))\n",
    "    grad_ndvi_pix = grad_ndvi.load()\n",
    "\n",
    "    for x in range(len(ndvi_pix)):\n",
    "        for y in range(len(ndvi_pix[x])):\n",
    "            print(f\"On pixel: [{x}, {y}]\", end=\"\\r\")\n",
    "            ndvi_value = ndvi_pix[x][y][0]\n",
    "            color = tuple(int(c * 255) for c in map_to_gradient(ndvi_value)[:3])\n",
    "            grad_ndvi_pix[x,y] = color\n",
    "    grad_ndvi.save(gradient_path + \"gradient_ndvi\" + str(stamp) + \".jpg\")\n",
    "    print(\"grad saved\")\n",
    "\n",
    "'''\n",
    "Driver method that handles the conversion of mono ndvi maps to gradient maps\n",
    "\n",
    "TODO:   Correct timestamping for model outputs. Right now it just adds a prefix to the beginning of the file name\n",
    "        so if there is already a timestamp appended to the end it works fine, otherwise won't work with pairing\n",
    "        functions as currently implemented.\n",
    "'''\n",
    "def generate_ndvi_gradient_dir(ndvi_dir, gradient_dir):\n",
    "    ndvi_list = os.listdir(ndvi_dir)\n",
    "    timestamps = get_timestamps(ndvi_dir)[1]\n",
    "    for i in range(len(ndvi_list)):\n",
    "        ndvi_path = os.path.join(ndvi_dir,ndvi_list[i])\n",
    "        stamp = i\n",
    "        create_ndvi_gradient_image(ndvi_path, gradient_dir, stamp)\n",
    "        print(f\"Generating Gradient NDVI Map: {i+1}/{len(ndvi_list)} images saved to {gradient_dir}\\t\\t\\t\\t\\t\\t\\t\\t\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validtion and Analysis Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Using full images resized to the input size as input. Consider splitting the image, running the model, then stitching the outputs.\n",
    "'''\n",
    "\n",
    "# Define Raw Directories\n",
    "noir_raw = \"validate/noir/\"\n",
    "rgb_raw = \"validate/rgb/\"\n",
    "red_raw = \"validate/red/\"\n",
    "\n",
    "# Define Final Processed Directories\n",
    "red_mono = \"validate/red/\"\n",
    "rgb_dir = \"validate/rgb/\"\n",
    "nir_mono = \"validate/noir/\"\n",
    "ndvi_mono = \"validate/ndvi/\"\n",
    "ndvi_grad = \"validate/ndvigrad/\"\n",
    "\n",
    "clean_nonpairs(noir_raw, rgb_raw)\n",
    "resize_dir(rgb_raw, rgb_dir, (256,256))\n",
    "resize_dir(noir_raw, nir_mono,(256,256))\n",
    "make_red_mono(rgb_dir, red_mono)\n",
    "generate_ndvi_dir(red_mono, nir_mono, ndvi_mono) # This takes WAY too much memory to process, so make sure to split RGB, NIR, and RED MONO before this step\n",
    "generate_ndvi_gradient_dir(ndvi_mono, ndvi_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Resizing images to 2560x2560 from ~4k and splitting into 10x10 grid \n",
    "'''\n",
    "\n",
    "# Define Raw Directories\n",
    "noir_raw = \"_raw/noir/\"\n",
    "rgb_raw = \"_raw/rgb/\"\n",
    "\n",
    "# Define Mid-Processed Directories\n",
    "rgb_mid = \"rgb/\"\n",
    "nir_mid = \"nir_mono/\"\n",
    "red_mid = \"red_mono/\"\n",
    "\n",
    "# Define Final Processed Directories\n",
    "red_mono = \"split_dataset/RED_MONO/\"\n",
    "rgb_dir = \"split_dataset/RGB/\"\n",
    "nir_mono = \"split_dataset/NIR_MONO/\"\n",
    "ndvi_mono = \"split_dataset/NDVI_MONO/\"\n",
    "ndvi_grad = \"split_dataset/ndvigrad/\"\n",
    "\n",
    "clean_nonpairs(noir_raw, rgb_raw)\n",
    "make_ir_mono(noir_raw, noir_raw)\n",
    "resize_dir(rgb_raw, rgb_mid, (2560,2560))\n",
    "resize_dir(noir_raw, nir_mid,(2560,2560))\n",
    "align_dir(nir_mid, rgb_mid)\n",
    "make_red_mono(rgb_mid, red_mid)\n",
    "split_dir(rgb_mid, rgb_dir, [10,10])\n",
    "split_dir(red_mid, red_mono,[10,10])\n",
    "split_dir(nir_mid, nir_mono,[10,10])\n",
    "generate_ndvi_dir(red_mono, nir_mono, ndvi_mono) # This takes WAY too much RAM to process, so make sure to split RGB, NIR, and RED MONO before this step\n",
    "generate_ndvi_gradient_dir(ndvi_mono, ndvi_grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
